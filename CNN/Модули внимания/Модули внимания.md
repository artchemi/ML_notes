[[Channel Attention Module]]

Механизм [Attention](https://arxiv.org/abs/1807.06521) (внимания) призван подсказывать сети, куда смотреть, но также и улучшать представление того, на чем фокусируется. Поскольку конволюция, извлекая признаки, смешивает канальную и пространственную информацию, мы применим модуль, чтобы выделить важное по этим двум направлениям отдельно (два отдельных модуля внимания еще и требует меньше дополнительных параметров и вычислений).

Модуль получается легким и широко применимым, при этом он заметно улучшает результаты по сравнению с обычными сверточными сетями.
Получая на вход feature map размерности `C×H×W` модуль производит `C×1×1` карту внимания для каналов ($M_c$) и `1×H×W` карту внимания для пространственных данных ($M_s$).