---
noteID: a0aa583d-5fbd-4140-982b-5fab83131746
tags:
  - Attention
---
**Пространственный модуль внимания** (англ. _spatial attention module_) реализуется за счет исследования пространственных взаимосвязей, то есть пытается извлечь информацию из взаимного расположения пикселей. В отличие от канального фокусируется на том, "где" находится информация во входных данных. В данном случае для сжатия размерности используются те же [пулинги](https://neerc.ifmo.ru/wiki/index.php?title=%D0%A1%D0%B2%D0%B5%D1%80%D1%82%D0%BE%D1%87%D0%BD%D1%8B%D0%B5_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5_%D1%81%D0%B5%D1%82%D0%B8#.D0.9F.D1.83.D0.BB.D0.B8.D0.BD.D0.B3.D0.BE.D0.B2.D1.8B.D0.B9_.D1.81.D0.BB.D0.BE.D0.B9 "Сверточные нейронные сети"), но относительно измерения $C$. Таким образом на выходе мы получаем две матрицы $F^s_{max}$ и $F^s_{avg}$ из $R^{H×W}$. После чего они конкатенируются и к полученному тензору размерности $R^{2×H×W}$ применяется [свертка](https://neerc.ifmo.ru/wiki/index.php?title=%D0%A1%D0%B2%D0%B5%D1%80%D1%82%D0%BE%D1%87%D0%BD%D1%8B%D0%B5_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5_%D1%81%D0%B5%D1%82%D0%B8#.D0.A1.D0.B2.D0.B5.D1.80.D1.82.D0.BA.D0.B0 "Сверточные нейронные сети"), уменьшающая число каналов до одного и не меняющая остальные размерности, а к результату поэлементно применяется сигмоидная функция активации. Полученный тензор из $R^{1×H×W}$ как раз является результатом применения $A_2(F1)$, поэлементное произведение которого с $F_1$ дает выходной тензор $F_2$, который называется выходным множеством признаков c размерностью $R^{C×H×W}$.
![[Pasted image 20250612152453.png]]
Применяем average-pooling и max-pooling вдоль оси каналов (получим размерность 1×H×W) и конкатенируем выходы для получения дескриптора, и затем применяем к нему свертку. Размер ядра свертки 7х7.

### $$M_s(F) = \sigma(f^{7×7}(AvgPool(F), MaxPool(F)))$$
